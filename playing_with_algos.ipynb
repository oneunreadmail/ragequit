{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import model_selection, ensemble\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (6,) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-249-a4785e1f59fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-249-a4785e1f59fd>\u001b[0m in \u001b[0;36mexpand\u001b[0;34m(array, k)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6,) (2,) "
     ]
    }
   ],
   "source": [
    "def expand(array, k=0):\n",
    "    k = np.array(k).T\n",
    "    return (array - 0.5) * (1 + k) + 0.5\n",
    "\n",
    "a = np.array([0.3, 0.4, 0.5, 0.9, 1, 2])\n",
    "expand(a, [0, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ML():\n",
    "    model = None\n",
    "    errors = None\n",
    "    log_loss = None\n",
    "    \n",
    "    def __init__(self, x1, x2, y1, y2, model):\n",
    "        self.x1, self.y1, self.x2, self.y2 = x1, y1, x2, y2\n",
    "        self.model = model\n",
    "        self.fit()\n",
    "    \n",
    "    def fit(self):\n",
    "        self.model.fit(self.x1, self.y1)\n",
    "        #values\n",
    "        y1v, y2v = self.model.predict(self.x1), self.model.predict(self.x2)\n",
    "        #probabilities\n",
    "        y1p, y2p = self.model.predict_proba(self.x1), self.model.predict_proba(self.x2)\n",
    "        self.errors = np.mean(self.y1 != y1v), np.mean(self.y2 != y2v)\n",
    "        self.log_loss = log_loss(self.y1, y1p, eps=1e-15), log_loss(self.y2, y2p, eps=1e-15)\n",
    "        self.l\n",
    "        importances = self.model.feature_importances_\n",
    "    \n",
    "    def dump(self, data):\n",
    "        a = self.model.predict_proba(data)\n",
    "        np.savetxt(\"data/y_test.csv\", a[:,1], fmt='%10.5f')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xytte = pd.read_csv(\"data/xytte.csv\")\n",
    "\n",
    "####################### ВНИМАНИЕ #######################\n",
    "# здесь трейн это которые в задаче трейн, с ответами\n",
    "# тест без ответов\n",
    "# но дальше в алгоритмах трейн будет разбиваться на два подсета\n",
    "# которые будут у меня называться x1-y1 и x2-y2, а по смыслу как раз трейн и тест\n",
    "# надо не перепутать\n",
    "\n",
    "x_train = xytte[xytte.returned == xytte.returned].reset_index(drop=True).drop(\"returned\", axis=1)\n",
    "y_train = xytte[xytte.returned == xytte.returned].reset_index(drop=True)[[\"returned\"]]\n",
    "x_test  = xytte[xytte.returned != xytte.returned].reset_index(drop=True).drop(\"returned\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# проверяем, что нигде не налажали\n",
    "# читаем из файла оригинальные данные\n",
    "\n",
    "x_test_ref = pd.read_csv(\"data/x_test.csv\", sep=\";\", dtype=np.float32)\n",
    "x_train_ref = pd.read_csv(\"data/x_train.csv\", sep=\";\", dtype=np.float32)\n",
    "y_train_ref = pd.read_csv(\"data/y_train.csv\", sep=\";\", dtype=np.float32, header=None, names=[\"returned\"])\n",
    "\n",
    "# заводим функцию на сравнение таблиц\n",
    "\n",
    "def df_equal(df1, df2):\n",
    "    if list(df1.columns) != list(df2.columns): \n",
    "        print(\"Mismatch columns:\")\n",
    "        print(\"df1: \", list(df1.columns))\n",
    "        print(\"df2: \", list(df2.columns))\n",
    "        return False\n",
    "    if list(df1.index) != list(df2.index): \n",
    "        print(\"Mismatch index:\")\n",
    "        print(\"df1: \", list(df1.columns)[0], \":\", list(df1.columns)[-1])\n",
    "        print(\"df2: \", list(df2.columns)[0], \":\", list(df2.columns)[-1])\n",
    "        return False\n",
    "    \n",
    "    ne_stacked = (df1 != df2).stack()\n",
    "    changed = ne_stacked[ne_stacked]\n",
    "    changed.index.names = ['id', 'col']\n",
    "\n",
    "    difference_locations = np.where(df1 != df2)\n",
    "    changed_from = df1.values[difference_locations]\n",
    "    changed_to = df2.values[difference_locations]\n",
    "    diff = pd.DataFrame({'from': changed_from, 'to': changed_to}, index=changed.index)\n",
    "    return not diff[diff[\"from\"] - diff[\"to\"] > 0.000001].count()[0]\n",
    "\n",
    "# ассертим наши таблицы\n",
    "\n",
    "assert(df_equal(x_test[x_test_ref.columns], x_test_ref))\n",
    "assert(df_equal(x_train[x_train_ref.columns], x_train_ref))\n",
    "assert(df_equal(y_train, y_train_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "params_all = list(x_train.columns)\n",
    "\n",
    "params_orig = [\n",
    "'maxPlayerLevel',\n",
    "'numberOfAttemptedLevels',\n",
    "'attemptsOnTheHighestLevel',\n",
    "'totalNumOfAttempts',\n",
    "'averageNumOfTurnsPerCompletedLevel',\n",
    "'numberOfBoostersUsed',\n",
    "'fractionOfUsefullBoosters',\n",
    "'totalScore',\n",
    "'totalBonusScore',\n",
    "'totalStarsCount',\n",
    "'numberOfDaysActuallyPlayed',\n",
    "]\n",
    "     \n",
    "params_mod = [\n",
    "#'attemptsOnTheHighestLevel_dvd',\n",
    "'attemptsOnTheHighestLevel_ln',\n",
    "'attemptsPerDay',\n",
    "'averageNumOfTurnsPerCompletedLevel_dvd',\n",
    "'maxPlayerLevel_ln',\n",
    "'numberOfAttemptedLevels_dvd',\n",
    "#'numberOfBoostersUsed_dvd',\n",
    "'numberOfBoostersUsed_dvd_ln',\n",
    "#'numberOfBoostersUsed_ln',\n",
    "'numberOfDaysActuallyPlayed_ln',\n",
    "'totalBonusScore_dvd',\n",
    "'totalNumOfAttempts_ln',\n",
    "#'totalScore_ln',\n",
    "'totalScore_ln_dvd',\n",
    "#'totalStarsCount_dvd',\n",
    "'totalStarsCount_dvd_ln',\n",
    "#'totalStarsCount_ln',\n",
    "]\n",
    "\n",
    "params_bool = [\n",
    "'allAttemptsOnTheHighestLevel',\n",
    "'attLevelsMoreThanMaxLevel',\n",
    "'doReturnOnLowerLevels',\n",
    "'zeroTotalScore',\n",
    "'zeroTurnsPerCompletedLevel'\n",
    "]\n",
    "\n",
    "params_orig_norm = [\n",
    "'attemptsOnTheHighestLevel_norm',\n",
    "'attemptsPerDay_norm',\n",
    "#'numberOfBoostersUsed_norm',\n",
    "#'maxPlayerLevel_norm',\n",
    "'fractionOfUsefullBoosters_norm',\n",
    "#'averageNumOfTurnsPerCompletedLevel_norm',\n",
    "'numberOfDaysActuallyPlayed_norm',\n",
    "'totalNumOfAttempts_norm',\n",
    "'totalBonusScore_norm',\n",
    "'totalScore_norm',\n",
    "'totalStarsCount_norm',\n",
    "]\n",
    "\n",
    "params_mod_norm = [\n",
    "'attemptsOnTheHighestLevel_dvd_norm',\n",
    "#'attemptsOnTheHighestLevel_ln_norm',\n",
    "'averageNumOfTurnsPerCompletedLevel_dvd_norm',\n",
    "'maxPlayerLevel_ln_norm',\n",
    "'numberOfAttemptedLevels_dvd_norm',\n",
    "#'numberOfAttemptedLevels_norm',\n",
    "'numberOfBoostersUsed_dvd_ln_norm',\n",
    "#'numberOfBoostersUsed_dvd_norm',\n",
    "#'numberOfBoostersUsed_ln_norm',\n",
    "'numberOfDaysActuallyPlayed_ln_norm',\n",
    "'totalBonusScore_dvd_norm',\n",
    "'totalNumOfAttempts_ln_norm',\n",
    "'totalScore_ln_dvd_norm',\n",
    "#'totalScore_ln_norm',\n",
    "'totalStarsCount_dvd_ln_norm',\n",
    "#'totalStarsCount_dvd_norm',\n",
    "'totalStarsCount_ln_norm',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#params = params_orig + [\"doReturnOnLowerLevels\"]\n",
    "#params = params_mod_norm + params_bool\n",
    "#params = params_bool\n",
    "#params = params_bool + params_orig\n",
    "params = params_all\n",
    "#params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_train_feed = x_train[params]\n",
    "x_test_feed = x_test[params]\n",
    "y_train_feed = list(y_train.returned)\n",
    "#y_test_feed = list(y_test)\n",
    "\n",
    "x1, x2, y1, y2 = train_test_split(x_train_feed, y_train_feed, test_size = 0.3)\n",
    "\n",
    "assert(set(list(x_train_feed.columns)) == set(list(x_test_feed.columns)))\n",
    "assert(set(list(x1.columns)) == set(list(x2.columns)))\n",
    "assert(type(y1) == list)\n",
    "assert(type(y2) == list)\n",
    "assert(len(y1) == len(x1.index))\n",
    "assert(len(y2) == len(x2.index))\n",
    "\n",
    "#list(x1.columns), list(x2.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "RF = ML(x1, x2, y1, y2, ensemble.RandomForestClassifier(n_estimators=100, max_features=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.11216728948753932, 0.55514760338745739)\n"
     ]
    }
   ],
   "source": [
    "print(RF.log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GB = ML(x1, x2, y1, y2, ensemble.GradientBoostingClassifier(n_estimators=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.30715460517578957, 0.39342845090670425)\n"
     ]
    }
   ],
   "source": [
    "print(GB.log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XGB = ML(x1, x2, y1, y2, xgb.XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.365213331878804, 0.3866148772270776)\n"
     ]
    }
   ],
   "source": [
    "print(XGB.log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = XGB.dump(x_test_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "importances = RF.model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f, idx in enumerate(indices):\n",
    "    print(\"{:2d}. feature '{:5s}' ({:.4f})\".format(f + 1, params[idx], importances[idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
