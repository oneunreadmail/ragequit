{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import model_selection, ensemble\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xytte = pd.read_csv(\"data/xytte.csv\")\n",
    "\n",
    "####################### ВНИМАНИЕ #######################\n",
    "# здесь трейн это которые в задаче трейн, с ответами\n",
    "# тест без ответов\n",
    "# но дальше в алгоритмах трейн будет разбиваться на два подсета\n",
    "# которые будут у меня называться x1-y1 и x2-y2, а по смыслу как раз трейн и тест\n",
    "# надо не перепутать\n",
    "\n",
    "x_train = xytte[xytte.returned == xytte.returned].reset_index().drop(\"returned\", axis=1)\n",
    "y_train = xytte[xytte.returned == xytte.returned].reset_index()[[\"returned\"]]\n",
    "x_test  = xytte[xytte.returned != xytte.returned].reset_index().drop(\"returned\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# проверяем, что нигде не налажали\n",
    "# читаем из файла оригинальные данные\n",
    "\n",
    "x_test_ref = pd.read_csv(\"data/x_test.csv\", sep=\";\", dtype=np.float32)\n",
    "x_train_ref = pd.read_csv(\"data/x_train.csv\", sep=\";\", dtype=np.float32)\n",
    "y_train_ref = pd.read_csv(\"data/y_train.csv\", sep=\";\", dtype=np.float32, header=None, names=[\"returned\"])\n",
    "\n",
    "# заводим функцию на сравнение таблиц\n",
    "\n",
    "def df_equal(df1, df2):\n",
    "    if list(df1.columns) != list(df2.columns): \n",
    "        print(\"Mismatch columns:\")\n",
    "        print(\"df1: \", list(df1.columns))\n",
    "        print(\"df2: \", list(df2.columns))\n",
    "        return False\n",
    "    if list(df1.index) != list(df2.index): \n",
    "        print(\"Mismatch index:\")\n",
    "        print(\"df1: \", list(df1.columns)[0], \":\", list(df1.columns)[-1])\n",
    "        print(\"df2: \", list(df2.columns)[0], \":\", list(df2.columns)[-1])\n",
    "        return False\n",
    "    \n",
    "    ne_stacked = (df1 != df2).stack()\n",
    "    changed = ne_stacked[ne_stacked]\n",
    "    changed.index.names = ['id', 'col']\n",
    "\n",
    "    difference_locations = np.where(df1 != df2)\n",
    "    changed_from = df1.values[difference_locations]\n",
    "    changed_to = df2.values[difference_locations]\n",
    "    diff = pd.DataFrame({'from': changed_from, 'to': changed_to}, index=changed.index)\n",
    "    return not diff[diff[\"from\"] - diff[\"to\"] > 0.000001].count()[0]\n",
    "\n",
    "# ассертим наши таблицы\n",
    "\n",
    "assert(df_equal(x_test[x_test_ref.columns], x_test_ref))\n",
    "assert(df_equal(x_train[x_train_ref.columns], x_train_ref))\n",
    "assert(df_equal(y_train, y_train_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "params_orig = [\n",
    "     'maxPlayerLevel',\n",
    "     'numberOfAttemptedLevels',\n",
    "     'attemptsOnTheHighestLevel',\n",
    "     'totalNumOfAttempts',\n",
    "     'averageNumOfTurnsPerCompletedLevel',\n",
    "     'numberOfBoostersUsed',\n",
    "     'fractionOfUsefullBoosters',\n",
    "     'totalScore',\n",
    "     'totalBonusScore',\n",
    "     'totalStarsCount',\n",
    "     'numberOfDaysActuallyPlayed',\n",
    "]\n",
    "     \n",
    "params_mod = [\n",
    "     #'attemptsOnTheHighestLevel_dvd',\n",
    "     'attemptsOnTheHighestLevel_ln',\n",
    "     'attemptsPerDay',\n",
    "     'averageNumOfTurnsPerCompletedLevel_dvd',\n",
    "     'maxPlayerLevel_ln',\n",
    "     'numberOfAttemptedLevels_dvd',\n",
    "     #'numberOfBoostersUsed_dvd',\n",
    "     'numberOfBoostersUsed_dvd_ln',\n",
    "     #'numberOfBoostersUsed_ln',\n",
    "     'numberOfDaysActuallyPlayed_ln',\n",
    "     'totalBonusScore_dvd',\n",
    "     'totalNumOfAttempts_ln',\n",
    "     #'totalScore_ln',\n",
    "     'totalScore_ln_dvd',\n",
    "     #'totalStarsCount_dvd',\n",
    "     'totalStarsCount_dvd_ln',\n",
    "     #'totalStarsCount_ln',\n",
    "]\n",
    "\n",
    "params_bool = [\n",
    "     'allAttemptsOnTheHighestLevel',\n",
    "     'attLevelsMoreThanMaxLevel',\n",
    "     'doReturnOnLowerLevels',\n",
    "     'zeroTotalScore',\n",
    "     'zeroTurnsPerCompletedLevel'\n",
    "]\n",
    "\n",
    "params_mod_norm = [\n",
    "     'attemptsOnTheHighestLevel_dvd_norm',\n",
    "     #'attemptsOnTheHighestLevel_ln_norm',\n",
    "     #'attemptsOnTheHighestLevel_norm',\n",
    "     'attemptsPerDay_norm',\n",
    "     'averageNumOfTurnsPerCompletedLevel_dvd_norm',\n",
    "     #'averageNumOfTurnsPerCompletedLevel_norm',\n",
    "     'fractionOfUsefullBoosters_norm',\n",
    "     'maxPlayerLevel_ln_norm',\n",
    "     #'maxPlayerLevel_norm',\n",
    "     'numberOfAttemptedLevels_dvd_norm',\n",
    "     #'numberOfAttemptedLevels_norm',\n",
    "     'numberOfBoostersUsed_dvd_ln_norm',\n",
    "     #'numberOfBoostersUsed_dvd_norm',\n",
    "     #'numberOfBoostersUsed_ln_norm',\n",
    "     #'numberOfBoostersUsed_norm',\n",
    "     'numberOfDaysActuallyPlayed_ln_norm',\n",
    "     #'numberOfDaysActuallyPlayed_norm',\n",
    "     'totalBonusScore_dvd_norm',\n",
    "     #'totalBonusScore_norm',\n",
    "     'totalNumOfAttempts_ln_norm',\n",
    "     #'totalNumOfAttempts_norm',\n",
    "     'totalScore_ln_dvd_norm',\n",
    "     #'totalScore_ln_norm',\n",
    "     #'totalScore_norm',\n",
    "     'totalStarsCount_dvd_ln_norm',\n",
    "     #'totalStarsCount_dvd_norm',\n",
    "     'totalStarsCount_ln_norm',\n",
    "     #'totalStarsCount_norm',\n",
    "]\n",
    "\n",
    "params = params_orig + [\"doReturnOnLowerLevels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17702 7587\n"
     ]
    }
   ],
   "source": [
    "x_train_feed = x_train[params]\n",
    "x_test_feed = x_test[params]\n",
    "y_train_feed = list(y_train.returned)\n",
    "#y_test_feed = list(y_test)\n",
    "\n",
    "x1, x2, y1, y2 = train_test_split(x_train_feed, y_train_feed, test_size = 0.3)\n",
    "\n",
    "N_train, _ = x1.shape \n",
    "N_test,  _ = x2.shape \n",
    "print(N_train, N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00875607276014 0.175695268222\n",
      "0.00920799909615 0.178858573876\n",
      "0.00847361880014 0.181494661922\n",
      "0.00451926336007 0.173454593383\n",
      "0.00463224494407 0.176881507842\n",
      "0.00474522652808 0.17674970344\n",
      "0.00423680940007 0.170291287729\n",
      "0.00434979098407 0.175431659417\n",
      "0.00429330019207 0.174640833004\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "estimators_list = [20, 50, 100]\n",
    "features_list = [3, 5, 7]\n",
    "for estimators in estimators_list:\n",
    "    for features in features_list:\n",
    "        rf = ensemble.RandomForestClassifier(n_estimators=estimators, random_state=35, max_features=features)\n",
    "        rf.fit(x1, y1)\n",
    "        err_train = np.mean(y1 != rf.predict(x1))\n",
    "        err_test  = np.mean(y2  != rf.predict(x2))\n",
    "        print(err_train, err_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      " 1. feature 'numberOfDaysActuallyPlayed' (0.2571)\n",
      " 2. feature 'totalNumOfAttempts' (0.1626)\n",
      " 3. feature 'averageNumOfTurnsPerCompletedLevel' (0.1100)\n",
      " 4. feature 'totalScore' (0.1095)\n",
      " 5. feature 'maxPlayerLevel' (0.0829)\n",
      " 6. feature 'totalBonusScore' (0.0660)\n",
      " 7. feature 'numberOfBoostersUsed' (0.0469)\n",
      " 8. feature 'totalStarsCount' (0.0467)\n",
      " 9. feature 'fractionOfUsefullBoosters' (0.0436)\n",
      "10. feature 'attemptsOnTheHighestLevel' (0.0425)\n",
      "11. feature 'numberOfAttemptedLevels' (0.0239)\n",
      "12. feature 'doReturnOnLowerLevels' (0.0081)\n"
     ]
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Feature importances:\")\n",
    "for f, idx in enumerate(indices):\n",
    "    print(\"{:2d}. feature '{:5s}' ({:.4f})\".format(f + 1, params[idx], importances[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.168173087787 0.164623698432\n"
     ]
    }
   ],
   "source": [
    "# GRAD BOOST\n",
    "\n",
    "gbt = ensemble.GradientBoostingClassifier(n_estimators=100, random_state=11)\n",
    "gbt.fit(x1, y1)\n",
    "\n",
    "err_train = np.mean(y1 != gbt.predict(x1))\n",
    "err_test = np.mean(y2 != gbt.predict(x2))\n",
    "print(err_train, err_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.64%\n"
     ]
    }
   ],
   "source": [
    "# XGBOOST\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(x1, y1)\n",
    "\n",
    "y_pred = model.predict(x2)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y2, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "#log_loss(y_test_1D, predictions, eps=1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
