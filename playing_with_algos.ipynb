{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import model_selection, ensemble\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "def random_forest(x1, y1, x2, y2, n_estimators=20, max_features=5):\n",
    "    rf = ensemble.RandomForestClassifier(n_estimators=n_estimators, max_features=max_features)\n",
    "    rf.fit(x1, y1)\n",
    "    err_train = np.mean(y1 != rf.predict(x1))\n",
    "    err_test  = np.mean(y2  != rf.predict(x2))\n",
    "    return err_train, err_test\n",
    "\n",
    "# GRAD BOOST\n",
    "\n",
    "def grad_boost(x1, y1, x2, y2, n_estimators=20):\n",
    "    gbt = ensemble.GradientBoostingClassifier(n_estimators=n_estimators)\n",
    "    gbt.fit(x1, y1)\n",
    "    err_train = np.mean(y1 != gbt.predict(x1))\n",
    "    err_test = np.mean(y2 != gbt.predict(x2))\n",
    "    return err_train, err_test\n",
    "\n",
    "# XGBOOST\n",
    "\n",
    "def xgboost(x1, y1, x2, y2):\n",
    "    model = xgb.XGBClassifier()\n",
    "    model.fit(x1, y1)\n",
    "    err_train = np.mean(y1 != model.predict(x1))\n",
    "    err_test = np.mean(y2 != model.predict(x2))\n",
    "    return err_train, err_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xytte = pd.read_csv(\"data/xytte.csv\")\n",
    "\n",
    "####################### ВНИМАНИЕ #######################\n",
    "# здесь трейн это которые в задаче трейн, с ответами\n",
    "# тест без ответов\n",
    "# но дальше в алгоритмах трейн будет разбиваться на два подсета\n",
    "# которые будут у меня называться x1-y1 и x2-y2, а по смыслу как раз трейн и тест\n",
    "# надо не перепутать\n",
    "\n",
    "x_train = xytte[xytte.returned == xytte.returned].reset_index().drop(\"returned\", axis=1)\n",
    "y_train = xytte[xytte.returned == xytte.returned].reset_index()[[\"returned\"]]\n",
    "x_test  = xytte[xytte.returned != xytte.returned].reset_index().drop(\"returned\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# проверяем, что нигде не налажали\n",
    "# читаем из файла оригинальные данные\n",
    "\n",
    "x_test_ref = pd.read_csv(\"data/x_test.csv\", sep=\";\", dtype=np.float32)\n",
    "x_train_ref = pd.read_csv(\"data/x_train.csv\", sep=\";\", dtype=np.float32)\n",
    "y_train_ref = pd.read_csv(\"data/y_train.csv\", sep=\";\", dtype=np.float32, header=None, names=[\"returned\"])\n",
    "\n",
    "# заводим функцию на сравнение таблиц\n",
    "\n",
    "def df_equal(df1, df2):\n",
    "    if list(df1.columns) != list(df2.columns): \n",
    "        print(\"Mismatch columns:\")\n",
    "        print(\"df1: \", list(df1.columns))\n",
    "        print(\"df2: \", list(df2.columns))\n",
    "        return False\n",
    "    if list(df1.index) != list(df2.index): \n",
    "        print(\"Mismatch index:\")\n",
    "        print(\"df1: \", list(df1.columns)[0], \":\", list(df1.columns)[-1])\n",
    "        print(\"df2: \", list(df2.columns)[0], \":\", list(df2.columns)[-1])\n",
    "        return False\n",
    "    \n",
    "    ne_stacked = (df1 != df2).stack()\n",
    "    changed = ne_stacked[ne_stacked]\n",
    "    changed.index.names = ['id', 'col']\n",
    "\n",
    "    difference_locations = np.where(df1 != df2)\n",
    "    changed_from = df1.values[difference_locations]\n",
    "    changed_to = df2.values[difference_locations]\n",
    "    diff = pd.DataFrame({'from': changed_from, 'to': changed_to}, index=changed.index)\n",
    "    return not diff[diff[\"from\"] - diff[\"to\"] > 0.000001].count()[0]\n",
    "\n",
    "# ассертим наши таблицы\n",
    "\n",
    "assert(df_equal(x_test[x_test_ref.columns], x_test_ref))\n",
    "assert(df_equal(x_train[x_train_ref.columns], x_train_ref))\n",
    "assert(df_equal(y_train, y_train_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "params_orig = [\n",
    "'maxPlayerLevel',\n",
    "'numberOfAttemptedLevels',\n",
    "'attemptsOnTheHighestLevel',\n",
    "'totalNumOfAttempts',\n",
    "'averageNumOfTurnsPerCompletedLevel',\n",
    "'numberOfBoostersUsed',\n",
    "'fractionOfUsefullBoosters',\n",
    "'totalScore',\n",
    "'totalBonusScore',\n",
    "'totalStarsCount',\n",
    "'numberOfDaysActuallyPlayed',\n",
    "]\n",
    "     \n",
    "params_mod = [\n",
    "#'attemptsOnTheHighestLevel_dvd',\n",
    "'attemptsOnTheHighestLevel_ln',\n",
    "'attemptsPerDay',\n",
    "'averageNumOfTurnsPerCompletedLevel_dvd',\n",
    "'maxPlayerLevel_ln',\n",
    "'numberOfAttemptedLevels_dvd',\n",
    "#'numberOfBoostersUsed_dvd',\n",
    "'numberOfBoostersUsed_dvd_ln',\n",
    "#'numberOfBoostersUsed_ln',\n",
    "'numberOfDaysActuallyPlayed_ln',\n",
    "'totalBonusScore_dvd',\n",
    "'totalNumOfAttempts_ln',\n",
    "#'totalScore_ln',\n",
    "'totalScore_ln_dvd',\n",
    "#'totalStarsCount_dvd',\n",
    "'totalStarsCount_dvd_ln',\n",
    "#'totalStarsCount_ln',\n",
    "]\n",
    "\n",
    "params_bool = [\n",
    "'allAttemptsOnTheHighestLevel',\n",
    "'attLevelsMoreThanMaxLevel',\n",
    "'doReturnOnLowerLevels',\n",
    "'zeroTotalScore',\n",
    "'zeroTurnsPerCompletedLevel'\n",
    "]\n",
    "\n",
    "params_orig_norm = [\n",
    "'attemptsOnTheHighestLevel_norm',\n",
    "'attemptsPerDay_norm',\n",
    "#'numberOfBoostersUsed_norm',\n",
    "#'maxPlayerLevel_norm',\n",
    "'fractionOfUsefullBoosters_norm',\n",
    "#'averageNumOfTurnsPerCompletedLevel_norm',\n",
    "'numberOfDaysActuallyPlayed_norm',\n",
    "'totalNumOfAttempts_norm',\n",
    "'totalBonusScore_norm',\n",
    "'totalScore_norm',\n",
    "'totalStarsCount_norm',\n",
    "]\n",
    "\n",
    "params_mod_norm = [\n",
    "'attemptsOnTheHighestLevel_dvd_norm',\n",
    "#'attemptsOnTheHighestLevel_ln_norm',\n",
    "'averageNumOfTurnsPerCompletedLevel_dvd_norm',\n",
    "'maxPlayerLevel_ln_norm',\n",
    "'numberOfAttemptedLevels_dvd_norm',\n",
    "#'numberOfAttemptedLevels_norm',\n",
    "'numberOfBoostersUsed_dvd_ln_norm',\n",
    "#'numberOfBoostersUsed_dvd_norm',\n",
    "#'numberOfBoostersUsed_ln_norm',\n",
    "'numberOfDaysActuallyPlayed_ln_norm',\n",
    "'totalBonusScore_dvd_norm',\n",
    "'totalNumOfAttempts_ln_norm',\n",
    "'totalScore_ln_dvd_norm',\n",
    "#'totalScore_ln_norm',\n",
    "'totalStarsCount_dvd_ln_norm',\n",
    "#'totalStarsCount_dvd_norm',\n",
    "'totalStarsCount_ln_norm',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#params = params_orig + [\"doReturnOnLowerLevels\"]\n",
    "#params = params_mod + params_bool\n",
    "params = params_orig_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_train_feed = x_train[params]\n",
    "x_test_feed = x_test[params]\n",
    "y_train_feed = list(y_train.returned)\n",
    "#y_test_feed = list(y_test)\n",
    "\n",
    "x1, x2, y1, y2 = train_test_split(x_train_feed, y_train_feed, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.013614280872217829, 0.19282984051667326)\n",
      "(0.16964184837871427, 0.17279557137208382)\n",
      "(0.16715625353067451, 0.17411361539475417)\n"
     ]
    }
   ],
   "source": [
    "print(random_forest(x1, y1, x2, y2))\n",
    "print(grad_boost(x1, y1, x2, y2))\n",
    "print(xgboost(x1, y1, x2, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      " 1. feature 'numberOfDaysActuallyPlayed' (0.2684)\n",
      " 2. feature 'totalNumOfAttempts' (0.1543)\n",
      " 3. feature 'averageNumOfTurnsPerCompletedLevel' (0.1088)\n",
      " 4. feature 'totalScore' (0.1074)\n",
      " 5. feature 'maxPlayerLevel' (0.0861)\n",
      " 6. feature 'totalBonusScore' (0.0633)\n",
      " 7. feature 'numberOfBoostersUsed' (0.0480)\n",
      " 8. feature 'totalStarsCount' (0.0465)\n",
      " 9. feature 'fractionOfUsefullBoosters' (0.0434)\n",
      "10. feature 'attemptsOnTheHighestLevel' (0.0418)\n",
      "11. feature 'numberOfAttemptedLevels' (0.0245)\n",
      "12. feature 'doReturnOnLowerLevels' (0.0075)\n"
     ]
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Feature importances:\")\n",
    "for f, idx in enumerate(indices):\n",
    "    print(\"{:2d}. feature '{:5s}' ({:.4f})\".format(f + 1, params[idx], importances[idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
